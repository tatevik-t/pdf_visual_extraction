{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the current directory to Python path so we can import our modules\n",
        "sys.path.append('.')\n",
        "\n",
        "# Import our custom modules\n",
        "from pdf_visual_extract import run_pdf_visual_extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PDF Visual Extraction Demo\n",
        "\n",
        "This notebook shows how to use the PDF Visual Extraction library to extract text, tables, and figures from PDFs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Running PDF Visual Extraction...\n",
            "ðŸš€ Starting PDF Visual Extraction Pipeline\n",
            "ðŸ“„ PDF: ../data/2025q1-alphabet-earnings-release.pdf\n",
            "ðŸ“ Output: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release\n",
            "ðŸ“Š Max pages: 10\n",
            "\n",
            "============================================================\n",
            "STEP: PDF Text Extraction\n",
            "============================================================\n",
            "Extracting text from: ../data/2025q1-alphabet-earnings-release.pdf\n",
            "âœ… Text extraction completed!\n",
            "   Total pages: 10\n",
            "   Saved to: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/text_extraction/2025q1-alphabet-earnings-release_text.json\n",
            "\n",
            "============================================================\n",
            "STEP: PDF to Images Conversion\n",
            "============================================================\n",
            "Converting PDF to images...\n",
            "Converting PDF to images with DPI: 300\n",
            "Limiting to first 10 pages\n",
            "Saved page 1: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_000.png\n",
            "Saved page 2: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_001.png\n",
            "Saved page 3: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_002.png\n",
            "Saved page 4: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_003.png\n",
            "Saved page 5: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_004.png\n",
            "Saved page 6: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_005.png\n",
            "Saved page 7: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_006.png\n",
            "Saved page 8: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_007.png\n",
            "Saved page 9: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_008.png\n",
            "Saved page 10: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_009.png\n",
            "Successfully converted 10 pages to images\n",
            "âœ… PDF to images conversion completed!\n",
            "   Generated 10 images\n",
            "   Saved to: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images\n",
            "\n",
            "============================================================\n",
            "STEP: OpenAI VLM Table/Figure Detection\n",
            "============================================================\n",
            "Detecting tables and figures...\n",
            "Processing 10 images...\n",
            "Processing page 1/10: page_000.png\n",
            "Found 1 elements on page 1\n",
            "Processing page 2/10: page_001.png\n",
            "Found 1 elements on page 2\n",
            "Processing page 3/10: page_002.png\n",
            "Found 0 elements on page 3\n",
            "Processing page 4/10: page_003.png\n",
            "Found 1 elements on page 4\n",
            "Processing page 5/10: page_004.png\n",
            "Found 1 elements on page 5\n",
            "Processing page 6/10: page_005.png\n",
            "Error processing image ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_005.png: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ctQ9lK1kRrPj8y9vCWzwiRvC on tokens per min (TPM): Limit 60000, Used 60000, Requested 1148. Please try again in 1.148s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Found 0 elements on page 6\n",
            "Processing page 7/10: page_006.png\n",
            "Error processing image ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_006.png: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ctQ9lK1kRrPj8y9vCWzwiRvC on tokens per min (TPM): Limit 100000, Used 100000, Requested 1148. Please try again in 8h15m56.16s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Found 0 elements on page 7\n",
            "Processing page 8/10: page_007.png\n",
            "Error processing image ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_007.png: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ctQ9lK1kRrPj8y9vCWzwiRvC on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Found 0 elements on page 8\n",
            "Processing page 9/10: page_008.png\n",
            "Error processing image ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_008.png: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ctQ9lK1kRrPj8y9vCWzwiRvC on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Found 0 elements on page 9\n",
            "Processing page 10/10: page_009.png\n",
            "Error processing image ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/images/page_009.png: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-ctQ9lK1kRrPj8y9vCWzwiRvC on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Found 0 elements on page 10\n",
            "âœ… VLM detection completed!\n",
            "   Processed 10 pages\n",
            "   Found 4 elements\n",
            "   Saved to: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/visual_detection/2025q1-alphabet-earnings-release_tables_figures.json\n",
            "\n",
            "============================================================\n",
            "STEP: Table Injection\n",
            "============================================================\n",
            "Injecting tables into text...\n",
            "âœ… Table injection completed!\n",
            "   Final result saved to: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/text_extraction/2025q1-alphabet-earnings-release_with_tables.json\n",
            "\n",
            "============================================================\n",
            "STEP: Summary Report Generation\n",
            "============================================================\n",
            "âœ… Summary report generated!\n",
            "   Saved to: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release_pipeline_summary.md\n",
            "\n",
            "============================================================\n",
            "ðŸŽ‰ PDF VISUAL EXTRACTION PIPELINE COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "ðŸ“ All outputs saved to: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release\n",
            "ðŸ“Š Final result: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/text_extraction/2025q1-alphabet-earnings-release_with_tables.json\n",
            "ðŸ“‹ Summary report: ../demo_output/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release/2025q1-alphabet-earnings-release_pipeline_summary.md\n",
            "âœ… Extraction completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Run the extraction pipeline with concurrent processing and CSV export\n",
        "pdf_path = \"../data/2025q1-alphabet-earnings-release.pdf\"\n",
        "output_dir = \"../demo_output/2025q1-alphabet-earnings-release\"\n",
        "\n",
        "print(\"ðŸš€ Running PDF Visual Extraction with concurrent VLM processing...\")\n",
        "print(\"âš¡ Using 5 concurrent workers for faster processing\")\n",
        "print(\"ðŸ“ˆ CSV export enabled for table data\")\n",
        "\n",
        "# Run with concurrent processing (5 workers by default) and CSV export\n",
        "success = run_pdf_visual_extraction(\n",
        "    pdf_path, \n",
        "    output_dir, \n",
        "    max_pages=10,\n",
        "    export_md=True,\n",
        "    export_csv=True,  # Enable CSV export\n",
        "    force=False,\n",
        "    max_workers=5  # 5 concurrent workers for VLM processing\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"âœ… Extraction completed successfully!\")\n",
        "else:\n",
        "    print(\"âŒ Extraction failed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“„ Loading data from: ../demo_output/2025q1-alphabet-earnings-release/text_extraction/2025q1-alphabet-earnings-release_with_tables.json\n",
            "âœ… Loaded data for: 2025q1-alphabet-earnings-release\n",
            "ðŸ“Š Total pages: 10\n",
            "ðŸ“ PDF path: data/2025q1-alphabet-earnings-release.pdf\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Load the extracted JSON data\n",
        "json_file = os.path.join(output_dir, \"text_extraction\", \"2025q1-alphabet-earnings-release_with_tables.json\")\n",
        "\n",
        "print(f\"ðŸ“„ Loading data from: {json_file}\")\n",
        "\n",
        "with open(json_file, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"âœ… Loaded data for: {data['pdf_name']}\")\n",
        "print(f\"ðŸ“Š Total pages: {data['total_pages']}\")\n",
        "print(f\"ðŸ“ PDF path: {data['pdf_path']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Exploring extracted data...\n",
            "\n",
            "ðŸ“„ Page 1:\n",
            "   Text: 2,659 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 2:\n",
            "   Text: 2,717 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 3:\n",
            "   Text: 4,938 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 4:\n",
            "   Text: 1,962 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 5:\n",
            "   Text: 823 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 6:\n",
            "   Text: 1,941 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 7:\n",
            "   Text: 2,177 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 8:\n",
            "   Text: 2,212 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 9:\n",
            "   Text: 3,155 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“„ Page 10:\n",
            "   Text: 534 characters\n",
            "   Tables/Figures: 0\n",
            "\n",
            "ðŸ“Š Summary:\n",
            "   Total Tables: 0\n",
            "   Total Figures: 0\n",
            "   Total Elements: 0\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Explore the extracted data\n",
        "print(\"ðŸ” Exploring extracted data...\\n\")\n",
        "\n",
        "total_tables = 0\n",
        "total_figures = 0\n",
        "\n",
        "for page in data['pages']:\n",
        "    page_num = page['page_number']\n",
        "    text_length = len(page['text'])\n",
        "    tables = page.get('tables', [])\n",
        "    \n",
        "    print(f\"ðŸ“„ Page {page_num}:\")\n",
        "    print(f\"   Text: {text_length:,} characters\")\n",
        "    print(f\"   Tables/Figures: {len(tables)}\")\n",
        "    \n",
        "    for i, table in enumerate(tables, 1):\n",
        "        element_type = table.get('type', 'table')\n",
        "        description = table.get('description', 'No description')\n",
        "        confidence = table.get('confidence', 'N/A')\n",
        "        \n",
        "        print(f\"   {element_type.title()} {i}: {description[:50]}... (confidence: {confidence})\")\n",
        "        \n",
        "        if element_type == 'table':\n",
        "            total_tables += 1\n",
        "        elif element_type == 'figure':\n",
        "            total_figures += 1\n",
        "    \n",
        "    print()\n",
        "\n",
        "print(f\"ðŸ“Š Summary:\")\n",
        "print(f\"   Total Tables: {total_tables}\")\n",
        "print(f\"   Total Figures: {total_figures}\")\n",
        "print(f\"   Total Elements: {total_tables + total_figures}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ Sample Table Data:\n",
            "\n",
            "No tables with structured data found.\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Show sample table data\n",
        "print(\"ðŸ“‹ Sample Table Data:\\n\")\n",
        "\n",
        "# Find the first table with structured data\n",
        "sample_table = None\n",
        "for page in data['pages']:\n",
        "    for table in page.get('tables', []):\n",
        "        if table.get('type') == 'table' and table.get('structured_data'):\n",
        "            sample_table = table\n",
        "            break\n",
        "    if sample_table:\n",
        "        break\n",
        "\n",
        "if sample_table:\n",
        "    print(f\"Description: {sample_table['description']}\")\n",
        "    print(f\"Confidence: {sample_table['confidence']}\")\n",
        "    print(f\"Structured Data:\")\n",
        "    print(sample_table['structured_data'])\n",
        "else:\n",
        "    print(\"No tables with structured data found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ Loading Markdown report from: ../demo_output/2025q1-alphabet-earnings-release/exports/2025q1-alphabet-earnings-release_report.md\n",
            "âœ… Markdown report loaded!\n",
            "ðŸ“„ Length: 23,541 characters\n",
            "ðŸ“Š Lines: 471\n",
            "\n",
            "ðŸ“Š Markdown Content:\n",
            "   Tables: 0\n",
            "   Figures: 0\n",
            "   Total Elements: 0\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Load the Markdown report\n",
        "markdown_file = os.path.join(output_dir, \"exports\", \"2025q1-alphabet-earnings-release_report.md\")\n",
        "\n",
        "print(f\"ðŸ“ Loading Markdown report from: {markdown_file}\")\n",
        "\n",
        "with open(markdown_file, 'r', encoding='utf-8') as f:\n",
        "    markdown_content = f.read()\n",
        "\n",
        "print(f\"âœ… Markdown report loaded!\")\n",
        "print(f\"ðŸ“„ Length: {len(markdown_content):,} characters\")\n",
        "print(f\"ðŸ“Š Lines: {len(markdown_content.splitlines())}\")\n",
        "\n",
        "# Count tables and figures in markdown\n",
        "table_count = markdown_content.count('#### Table')\n",
        "figure_count = markdown_content.count('#### Figure')\n",
        "\n",
        "print(f\"\\nðŸ“Š Markdown Content:\")\n",
        "print(f\"   Tables: {table_count}\")\n",
        "print(f\"   Figures: {figure_count}\")\n",
        "print(f\"   Total Elements: {table_count + figure_count}\")\n",
        "\n",
        "# Step 6: Check for CSV files\n",
        "csv_dir = os.path.join(output_dir, \"exports\", \"csv_exports\")\n",
        "if os.path.exists(csv_dir):\n",
        "    csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "    print(f\"\\nðŸ“ˆ CSV Files Generated:\")\n",
        "    print(f\"   Directory: {csv_dir}\")\n",
        "    print(f\"   Count: {len(csv_files)}\")\n",
        "    \n",
        "    if csv_files:\n",
        "        print(f\"   Files:\")\n",
        "        for csv_file in csv_files[:5]:  # Show first 5 files\n",
        "            print(f\"     - {csv_file}\")\n",
        "        if len(csv_files) > 5:\n",
        "            print(f\"     ... and {len(csv_files) - 5} more\")\n",
        "else:\n",
        "    print(f\"\\nðŸ“ˆ No CSV files found (no tables detected)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“– Markdown Preview (first 1000 characters):\n",
            "\n",
            "==================================================\n",
            "# 2025Q1 Alphabet Earnings Release\n",
            "\n",
            "**Total Pages:** 10\n",
            "\n",
            "---\n",
            "\n",
            "## Page 2\n",
            "\n",
            "### Text Content\n",
            "\n",
            "Alphabet Announces First Quarter  2025  Results\n",
            "MOUNTAIN VIEW, Calif. â€“ April 24, 2025  â€“ Alphabet Inc. (NASDAQ: GOOG, GOOGL) today announced financial \n",
            "results for the quarter ended  March 31, 2025 .\n",
            "â€¢Consolidated  Alphabet revenues in Q1 2025 increased 12%, or 14% in constant currency, year over year to \n",
            "$90.2 billion  reflecting robust momentum across the business, with Google Search & other, YouTube ads, \n",
            "Google subscriptions, platforms, and devices, and Google Cloud each delivering double -digit growth rates. \n",
            "â€¢Google Services revenues increased 10% to $77.3 billion , reflecting strong performance across Google \n",
            "Search & other, Google subscriptions, platforms, and devices , and YouTube ads .\n",
            "â€¢Google Cloud revenues increased 28% to $12.3 billion , led by growth in Google Cloud Platform (GCP) \n",
            "across core GCP products, AI Infrastructure , and Generative AI Solutions.\n",
            "â€¢Total operating income in\n",
            "==================================================\n",
            "... (truncated)\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Show a preview of the Markdown content\n",
        "print(\"ðŸ“– Markdown Preview (first 1000 characters):\\n\")\n",
        "print(\"=\" * 50)\n",
        "print(markdown_content[:1000])\n",
        "print(\"=\" * 50)\n",
        "print(\"... (truncated)\")\n",
        "\n",
        "# Step 8: Show sample CSV content if available\n",
        "if os.path.exists(csv_dir) and csv_files:\n",
        "    print(f\"\\nðŸ“ˆ Sample CSV Content:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Show first CSV file\n",
        "    first_csv = os.path.join(csv_dir, csv_files[0])\n",
        "    with open(first_csv, 'r', encoding='utf-8') as f:\n",
        "        csv_content = f.read()\n",
        "    \n",
        "    print(f\"File: {csv_files[0]}\")\n",
        "    print(f\"Content (first 500 characters):\")\n",
        "    print(csv_content[:500])\n",
        "    print(\"=\" * 50)\n",
        "    print(\"... (truncated)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This demo shows how to:\n",
        "\n",
        "1. **Run the extraction pipeline** - Extract text, tables, and figures from PDFs\n",
        "2. **Load JSON data** - Access structured data for programmatic use\n",
        "3. **Explore extracted content** - See what was found on each page\n",
        "4. **View table data** - Access structured financial data\n",
        "5. **Load Markdown reports** - Get human-readable summaries\n",
        "6. **Export CSV files** - Get structured table data in CSV format\n",
        "\n",
        "### Key Features:\n",
        "- âœ… **Text extraction** from all pages\n",
        "- âœ… **Table detection** with structured data\n",
        "- âœ… **Figure detection** with descriptions\n",
        "- âœ… **CSV export** for table data using LLM\n",
        "- âœ… **Confidence scores** for quality assessment\n",
        "- âœ… **Multiple output formats** (JSON + Markdown + CSV)\n",
        "\n",
        "### Perfect for RAG Systems:\n",
        "- **Structured data** for precise queries\n",
        "- **Text content** for semantic search\n",
        "- **CSV files** for data analysis and import\n",
        "- **Source attribution** with page numbers\n",
        "- **Quality metrics** with confidence scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ Performance Benefits of Concurrent Processing\n",
        "\n",
        "The concurrent VLM processing provides significant speed improvements:\n",
        "\n",
        "### Before (Sequential):\n",
        "- 10 pages Ã— 3 seconds each = 30 seconds\n",
        "- One page at a time\n",
        "\n",
        "### After (Concurrent with 5 workers):\n",
        "- 10 pages Ã· 5 workers Ã— 3 seconds = 6 seconds\n",
        "- **5x faster processing!**\n",
        "\n",
        "### Configuration Options:\n",
        "- `max_workers=3`: Conservative (good for rate limits)\n",
        "- `max_workers=5`: Balanced (default)\n",
        "- `max_workers=10`: Aggressive (for high-performance systems)\n",
        "\n",
        "### Rate Limiting:\n",
        "OpenAI has rate limits, so adjust `max_workers` based on your API tier:\n",
        "- Free tier: 1-2 workers\n",
        "- Pay-as-you-go: 3-5 workers  \n",
        "- Enterprise: 10+ workers\n",
        "\n",
        "## ðŸ“ˆ CSV Export Features\n",
        "\n",
        "The new CSV export functionality provides:\n",
        "\n",
        "### LLM-Powered Conversion:\n",
        "- **Intelligent parsing** of structured table data\n",
        "- **Clean CSV formatting** with proper headers\n",
        "- **Data type preservation** (numbers, text, percentages)\n",
        "- **Hierarchical structure** handling\n",
        "\n",
        "### Output Structure:\n",
        "- **CSV files** saved in `exports/csv_exports/` directory\n",
        "- **Descriptive filenames** with page numbers and table descriptions\n",
        "- **Conversion summary** with statistics and metadata\n",
        "- **Error handling** for failed conversions\n",
        "\n",
        "### Use Cases:\n",
        "- **Data analysis** in Excel, pandas, or other tools\n",
        "- **Database import** for structured storage\n",
        "- **API integration** for downstream processing\n",
        "- **RAG systems** with structured data queries\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
